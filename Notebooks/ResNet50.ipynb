{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTnoxCApAsvV"
   },
   "source": [
    "After Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17841,
     "status": "ok",
     "timestamp": 1755067381061,
     "user": {
      "displayName": "Bhawya Devi",
      "userId": "13879599296228198665"
     },
     "user_tz": -330
    },
    "id": "akfh70eVXOdE",
    "outputId": "9f1fdc73-d9dd-4eb1-8268-d5801f7c1871"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mzcEwaH7dNc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.optimizers import *\n",
    "from keras.metrics import *\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 5987,
     "status": "ok",
     "timestamp": 1755067396784,
     "user": {
      "displayName": "Bhawya Devi",
      "userId": "13879599296228198665"
     },
     "user_tz": -330
    },
    "id": "a5GLXFhC7ifV",
    "outputId": "c3637680-a1f3-4ece-b02f-0c85b1c427a2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 25331,\n  \"fields\": [\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25331,\n        \"samples\": [\n          \"ISIC_0000360\",\n          \"ISIC_0031596\",\n          \"ISIC_0069981\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MEL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3829544511327869,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49994146244555254,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3376071976055338,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AK\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18181492051429826,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BKL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30473197962790777,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09667692482007674,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VASC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09944041938641082,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1554930236360787,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UNK\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25331,\n        \"samples\": [\n          \"/content/drive/MyDrive/Final_Project/Classification/ISIC_2019_Training_Data/ISIC_0000360.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-06f7418f-6ae7-4230-8358-a704c09bc860\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>MEL</th>\n",
       "      <th>NV</th>\n",
       "      <th>BCC</th>\n",
       "      <th>AK</th>\n",
       "      <th>BKL</th>\n",
       "      <th>DF</th>\n",
       "      <th>VASC</th>\n",
       "      <th>SCC</th>\n",
       "      <th>UNK</th>\n",
       "      <th>type</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Melanocytic nevi]</td>\n",
       "      <td>/content/drive/MyDrive/Final_Project/Classific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Melanocytic nevi]</td>\n",
       "      <td>/content/drive/MyDrive/Final_Project/Classific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Melanoma]</td>\n",
       "      <td>/content/drive/MyDrive/Final_Project/Classific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Melanocytic nevi]</td>\n",
       "      <td>/content/drive/MyDrive/Final_Project/Classific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0000004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Melanoma]</td>\n",
       "      <td>/content/drive/MyDrive/Final_Project/Classific...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06f7418f-6ae7-4230-8358-a704c09bc860')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-06f7418f-6ae7-4230-8358-a704c09bc860 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-06f7418f-6ae7-4230-8358-a704c09bc860');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-22b7d89e-6c94-4fd2-9241-d12d6497311b\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22b7d89e-6c94-4fd2-9241-d12d6497311b')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-22b7d89e-6c94-4fd2-9241-d12d6497311b button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "          image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK  \\\n",
       "0  ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
       "1  ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
       "2  ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
       "3  ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
       "4  ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0   \n",
       "\n",
       "                 type                                               path  \n",
       "0  [Melanocytic nevi]  /content/drive/MyDrive/Final_Project/Classific...  \n",
       "1  [Melanocytic nevi]  /content/drive/MyDrive/Final_Project/Classific...  \n",
       "2          [Melanoma]  /content/drive/MyDrive/Final_Project/Classific...  \n",
       "3  [Melanocytic nevi]  /content/drive/MyDrive/Final_Project/Classific...  \n",
       "4          [Melanoma]  /content/drive/MyDrive/Final_Project/Classific...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define full lesion names\n",
    "type_dictionary = {\n",
    "    'MEL': 'Melanoma',\n",
    "    'NV': 'Melanocytic nevi',\n",
    "    'BCC': 'Basal cell carcinoma',\n",
    "    'AK': 'Actinic keratoses',\n",
    "    'BKL': 'Benign keratosis',\n",
    "    'DF': 'Dermatofibroma',\n",
    "    'VASC': 'Vascular skin lesions',\n",
    "    'SCC': 'Squamous cell carcinoma'\n",
    "}\n",
    "\n",
    "root_dir = '/content/drive/MyDrive/Final_Project/Classification/'\n",
    "\n",
    "# Load metadata and ground truth\n",
    "metadata_path = root_dir + 'ISIC_2019_Training_Metadata.csv'\n",
    "groundtruth_path = root_dir + 'ISIC_2019_Training_GroundTruth.csv'\n",
    "\n",
    "meta_df = pd.read_csv(metadata_path)\n",
    "gt_df = pd.read_csv(groundtruth_path)\n",
    "\n",
    "# Merge metadata and ground truth using 'image' column\n",
    "df = pd.merge(meta_df, gt_df, on='image')\n",
    "\n",
    "# Keep label columns as is (multi-label)\n",
    "label_columns = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC']\n",
    "\n",
    "# Map full names (optional, useful for display)\n",
    "df['type'] = df[label_columns].apply(lambda row: [type_dictionary[c] for c in label_columns if row[c] == 1], axis=1)\n",
    "\n",
    "# Add image path column\n",
    "df['path'] = root_dir + 'ISIC_2019_Training_Data/' + df['image'] + '.jpg'\n",
    "\n",
    "# Drop unnecessary columns except the label columns and image info\n",
    "cols_to_drop = ['lesion_id', 'sex', 'age_approx', 'anatom_site_general']\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Your df now has:\n",
    "# - image column (filename)\n",
    "# - path column (full path to image)\n",
    "# - label columns (binary 0/1 multi-label targets)\n",
    "# - type column (list of full lesion names present)\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BUAR_YE7sPZ"
   },
   "outputs": [],
   "source": [
    "# Get class weights\n",
    "y_train = np.argmax(df[label_columns].values, axis=1)  # Convert multi-label to single-label for weighting\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBomcRsd7ncD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomTranslation\n",
    "# ====== PATHS ======\n",
    "image_dir = \"/content/drive/MyDrive/Final_Project/Classification/preprocessed_data/images\"\n",
    "label_dir = \"/content/drive/MyDrive/Final_Project/Classification/preprocessed_data/labels\"\n",
    "\n",
    "\n",
    "# Use this instead of ImageDataGenerator\n",
    "img_augmentation = Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.2),\n",
    "    RandomZoom(0.15),\n",
    "    RandomTranslation(0.1, 0.1)\n",
    "])\n",
    "\n",
    "# ====== Load training paths ======\n",
    "train_image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.startswith(\"train_\")])\n",
    "train_label_paths = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.startswith(\"train_\")])\n",
    "\n",
    "# ====== Oversample labels ======\n",
    "y_raw = np.array([np.load(p) for p in train_label_paths])\n",
    "indices = np.arange(len(y_raw)).reshape(-1, 1)\n",
    "ros = RandomOverSampler()\n",
    "resampled_indices, _ = ros.fit_resample(indices, y_raw)\n",
    "\n",
    "# ====== Data Generators ======\n",
    "class BalancedNpyGenerator(Sequence):\n",
    "        def __init__(self, image_paths, label_paths, resampled_indices, batch_size=32, datagen=None):\n",
    "            self.image_paths = np.array(image_paths)[resampled_indices.flatten()]\n",
    "            self.label_paths = np.array(label_paths)[resampled_indices.flatten()]\n",
    "            self.batch_size = batch_size\n",
    "            self.datagen = datagen\n",
    "            self.label_values = np.array([np.load(p) for p in self.label_paths])\n",
    "\n",
    "        def __len__(self):\n",
    "            return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            # Stratified sampling for this batch\n",
    "            batch_indices = resample(\n",
    "                np.arange(len(self.image_paths)),\n",
    "                stratify=np.argmax(self.label_values, axis=1),\n",
    "                replace=True,\n",
    "                n_samples=self.batch_size\n",
    "            )\n",
    "\n",
    "            x = np.array([np.load(self.image_paths[i]) for i in batch_indices]).astype(np.float32)\n",
    "            y = np.array([np.load(self.label_paths[i]) for i in batch_indices]).astype(np.float32)\n",
    "            x = preprocess_input(x * 255.0)\n",
    "\n",
    "            if self.datagen:\n",
    "                  flow = self.datagen.flow(x, y, batch_size=self.batch_size, shuffle=False)\n",
    "                  x, y = next(flow)\n",
    "            return x, y\n",
    "\n",
    "# === Validation Generator ===\n",
    "val_image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.startswith(\"val_\")])\n",
    "val_label_paths = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.startswith(\"val_\")])\n",
    "\n",
    "class SimpleNpyGenerator(Sequence):\n",
    "    def __init__(self, image_paths, label_paths, batch_size=32):\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.array([np.load(p) for p in self.image_paths[idx*self.batch_size:(idx+1)*self.batch_size]]).astype(np.float32)\n",
    "        y = np.array([np.load(p) for p in self.label_paths[idx*self.batch_size:(idx+1)*self.batch_size]]).astype(np.float32)\n",
    "        x = x / 255.0\n",
    "        x = preprocess_input(x)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "\n",
    "# ====== Create Generators ======\n",
    "train_gen = BalancedNpyGenerator(\n",
    "    image_paths=train_image_paths,\n",
    "    label_paths=train_label_paths,\n",
    "    resampled_indices=resampled_indices,\n",
    "    batch_size=32,\n",
    "    datagen=ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.05,\n",
    "        brightness_range=[0.9, 1.1],\n",
    "        horizontal_flip=True\n",
    "    )\n",
    ")\n",
    "\n",
    "val_gen = SimpleNpyGenerator(val_image_paths, val_label_paths, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ckp_F4aX8l_E"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.metrics import AUC\n",
    "\n",
    "# === Set your phase: 1, 2, or 3 ===\n",
    "phase = 3  # Change this manually for next phase\n",
    "\n",
    "# === Directory to save weights and epoch progress ===\n",
    "weights_dir = \"/content/drive/MyDrive/Final_Project/Classification/Phase3_Augmented/reweights/\"\n",
    "weights_path = os.path.join(weights_dir, f\"resnet50_phase{phase}.weights.h5\")\n",
    "checkpoint_path = os.path.join(weights_dir, f\"resnet50_phase{phase}_checkpoint.weights.h5\")\n",
    "previous_weights_path = os.path.join(weights_dir, f\"resnet50_phase{phase - 1}.weights.h5\")\n",
    "epoch_file = os.path.join(weights_dir, f\"phase{phase}_last_epoch.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFH48UNJ87w4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8782,
     "status": "ok",
     "timestamp": 1755071894771,
     "user": {
      "displayName": "Bhawya Devi",
      "userId": "13879599296228198665"
     },
     "user_tz": -330
    },
    "id": "JcyvIJmv88MF",
    "outputId": "e6df2f76-207a-4cf0-b3e7-a67b52fcc4c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "def get_freeze_index(phase):\n",
    "    if phase == 1:\n",
    "        return len(keras.applications.ResNet50().layers)  # freeze all\n",
    "    elif phase == 2:\n",
    "        return -30  # unfreeze last 30 layers\n",
    "    elif phase == 3:\n",
    "         return -60\n",
    "    else:\n",
    "        raise ValueError(\"Phase must be 1, 2, or 3\")\n",
    "\n",
    "def build_model(freeze_until):\n",
    "    base = keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(75, 100, 3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "\n",
    "    for layer in base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    if freeze_until < 0:\n",
    "        for layer in base.layers[:freeze_until]:  # keep early layers frozen\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in base.layers[:freeze_until]:  # freeze first layers\n",
    "            layer.trainable = False\n",
    "\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "\n",
    "    model = Sequential([\n",
    "        base,\n",
    "        Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.3),\n",
    "        Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.5),  # Increased dropout to prevent overfitting\n",
    "        Dense(8, activation='sigmoid', kernel_regularizer=l2(0.001))  # Apply L2 here too\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "freeze_until = get_freeze_index(phase)\n",
    "model = build_model(freeze_until)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13906,
     "status": "ok",
     "timestamp": 1755071912508,
     "user": {
      "displayName": "Bhawya Devi",
      "userId": "13879599296228198665"
     },
     "user_tz": -330
    },
    "id": "WU4BiK6R88MG",
    "outputId": "546df8f2-1f75-4a0a-da78-d4fc78ed57f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Resuming from checkpoint: /content/drive/MyDrive/Final_Project/Classification/Phase3_Augmented/reweights/resnet50_phase3_checkpoint.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 158 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Adjust learning rate based on phase\n",
    "learning_rate = 1e-6\n",
    "\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def loss(y_true, y_pred):\n",
    "        pt = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        return -K.mean(alpha * K.pow(1 - pt, gamma) * K.log(pt + 1e-7))\n",
    "    return loss\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=focal_loss(),  # Changed to focal loss\n",
    "    metrics=['accuracy', AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Load weights\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\" Resuming from checkpoint: {checkpoint_path}\")\n",
    "    model.load_weights(checkpoint_path)\n",
    "elif phase > 1 and os.path.exists(previous_weights_path):\n",
    "    print(f\" Starting from previous phase weights: {previous_weights_path}\")\n",
    "    model.load_weights(previous_weights_path)\n",
    "else:\n",
    "    print(\" Starting fresh training\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbjOS5N588MH"
   },
   "outputs": [],
   "source": [
    "# Callback to save weights after every epoch\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch',\n",
    "    verbose=1\n",
    ")\n",
    "epoch_save =\"/content/drive/MyDrive/Final_Project/Classification/Phase3_Augmented/reweights/epoch_save\"\n",
    "epochwise_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(epoch_save, f\"resnet50_phase{phase}_epoch_\" + \"{epoch:02d}.weights.h5\"),\n",
    "    save_weights_only=True,\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch',\n",
    "    verbose=0  # Silent save; reduce log clutter\n",
    ")\n",
    "# Custom callback to save current epoch to .txt file\n",
    "class SaveEpochCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        with open(self.path, \"w\") as f:\n",
    "            f.write(str(epoch + 1))  # Save next epoch index\n",
    "\n",
    "save_epoch_cb = SaveEpochCallback(epoch_file)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc',\n",
    "    patience=5,\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KaSoFf688MI",
    "outputId": "fbf340be-e30a-4144-d485-b2e52893080c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Resuming from epoch 20\n",
      "Epoch 21/25\n",
      "\u001b[1m2318/2318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9585 - auc: 0.9987 - loss: 0.0262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: saving model to /content/drive/MyDrive/Final_Project/Classification/Phase3_Augmented/reweights/resnet50_phase3_checkpoint.weights.h5\n",
      "\u001b[1m2318/2318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9628s\u001b[0m 4s/step - accuracy: 0.9585 - auc: 0.9987 - loss: 0.0262 - val_accuracy: 0.5081 - val_auc: 0.8299 - val_loss: 0.0402 - learning_rate: 1.0000e-06\n",
      "Epoch 22/25\n",
      "\u001b[1m2318/2318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9617 - auc: 0.9989 - loss: 0.0251\n",
      "Epoch 22: saving model to /content/drive/MyDrive/Final_Project/Classification/Phase3_Augmented/reweights/resnet50_phase3_checkpoint.weights.h5\n",
      "\u001b[1m2318/2318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7927s\u001b[0m 3s/step - accuracy: 0.9617 - auc: 0.9989 - loss: 0.0251 - val_accuracy: 0.5081 - val_auc: 0.8299 - val_loss: 0.0403 - learning_rate: 1.0000e-06\n",
      "Epoch 23/25\n",
      "\u001b[1m2318/2318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9642 - auc: 0.9990 - loss: 0.0243\n",
      "Epoch 23: saving model to /content/drive/MyDrive/Final_Project/Classification/Phase3_Augmented/reweights/resnet50_phase3_checkpoint.weights.h5\n",
      "\u001b[1m2318/2318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7862s\u001b[0m 3s/step - accuracy: 0.9642 - auc: 0.9990 - loss: 0.0243 - val_accuracy: 0.5081 - val_auc: 0.8299 - val_loss: 0.0414 - learning_rate: 1.0000e-06\n",
      "Epoch 24/25\n",
      "\u001b[1m 156/2318\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:56:34\u001b[0m 3s/step - accuracy: 0.9666 - auc: 0.9990 - loss: 0.0241"
     ]
    }
   ],
   "source": [
    "# Read last completed epoch\n",
    "initial_epoch = 20\n",
    "if os.path.exists(epoch_file):\n",
    "    with open(epoch_file, \"r\") as f:\n",
    "        initial_epoch = int(f.read().strip())\n",
    "\n",
    "print(f\" Resuming from epoch {initial_epoch}\")\n",
    "\n",
    "# Train the model\n",
    "hist=model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    initial_epoch=initial_epoch,\n",
    "    epochs=25,\n",
    "    callbacks=[checkpoint_cb, save_epoch_cb , reduce_lr, early_stop, epochwise_checkpoint_cb],\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzqnnm1NMQ2F"
   },
   "outputs": [],
   "source": [
    "model.save_weights(weights_path)\n",
    "print(f\"✅ Final weights saved to: {weights_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1752819643253,
     "user": {
      "displayName": "Bhawya Devi",
      "userId": "13879599296228198665"
     },
     "user_tz": -330
    },
    "id": "1aJfH_c-IX6s",
    "outputId": "ae351b33-7698-4d77-d2d1-25bb886978d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_layer_2 False\n",
      "conv1_pad False\n",
      "conv1_conv False\n",
      "conv1_bn False\n",
      "conv1_relu False\n",
      "pool1_pad False\n",
      "pool1_pool False\n",
      "conv2_block1_1_conv False\n",
      "conv2_block1_1_bn False\n",
      "conv2_block1_1_relu False\n",
      "conv2_block1_2_conv False\n",
      "conv2_block1_2_bn False\n",
      "conv2_block1_2_relu False\n",
      "conv2_block1_0_conv False\n",
      "conv2_block1_3_conv False\n",
      "conv2_block1_0_bn False\n",
      "conv2_block1_3_bn False\n",
      "conv2_block1_add False\n",
      "conv2_block1_out False\n",
      "conv2_block2_1_conv False\n",
      "conv2_block2_1_bn False\n",
      "conv2_block2_1_relu False\n",
      "conv2_block2_2_conv False\n",
      "conv2_block2_2_bn False\n",
      "conv2_block2_2_relu False\n",
      "conv2_block2_3_conv False\n",
      "conv2_block2_3_bn False\n",
      "conv2_block2_add False\n",
      "conv2_block2_out False\n",
      "conv2_block3_1_conv False\n",
      "conv2_block3_1_bn False\n",
      "conv2_block3_1_relu False\n",
      "conv2_block3_2_conv False\n",
      "conv2_block3_2_bn False\n",
      "conv2_block3_2_relu False\n",
      "conv2_block3_3_conv False\n",
      "conv2_block3_3_bn False\n",
      "conv2_block3_add False\n",
      "conv2_block3_out False\n",
      "conv3_block1_1_conv False\n",
      "conv3_block1_1_bn False\n",
      "conv3_block1_1_relu False\n",
      "conv3_block1_2_conv False\n",
      "conv3_block1_2_bn False\n",
      "conv3_block1_2_relu False\n",
      "conv3_block1_0_conv False\n",
      "conv3_block1_3_conv False\n",
      "conv3_block1_0_bn False\n",
      "conv3_block1_3_bn False\n",
      "conv3_block1_add False\n",
      "conv3_block1_out False\n",
      "conv3_block2_1_conv False\n",
      "conv3_block2_1_bn False\n",
      "conv3_block2_1_relu False\n",
      "conv3_block2_2_conv False\n",
      "conv3_block2_2_bn False\n",
      "conv3_block2_2_relu False\n",
      "conv3_block2_3_conv False\n",
      "conv3_block2_3_bn False\n",
      "conv3_block2_add False\n",
      "conv3_block2_out False\n",
      "conv3_block3_1_conv False\n",
      "conv3_block3_1_bn False\n",
      "conv3_block3_1_relu False\n",
      "conv3_block3_2_conv False\n",
      "conv3_block3_2_bn False\n",
      "conv3_block3_2_relu False\n",
      "conv3_block3_3_conv False\n",
      "conv3_block3_3_bn False\n",
      "conv3_block3_add False\n",
      "conv3_block3_out False\n",
      "conv3_block4_1_conv False\n",
      "conv3_block4_1_bn False\n",
      "conv3_block4_1_relu False\n",
      "conv3_block4_2_conv False\n",
      "conv3_block4_2_bn False\n",
      "conv3_block4_2_relu False\n",
      "conv3_block4_3_conv False\n",
      "conv3_block4_3_bn False\n",
      "conv3_block4_add False\n",
      "conv3_block4_out False\n",
      "conv4_block1_1_conv False\n",
      "conv4_block1_1_bn False\n",
      "conv4_block1_1_relu False\n",
      "conv4_block1_2_conv False\n",
      "conv4_block1_2_bn False\n",
      "conv4_block1_2_relu False\n",
      "conv4_block1_0_conv False\n",
      "conv4_block1_3_conv False\n",
      "conv4_block1_0_bn False\n",
      "conv4_block1_3_bn False\n",
      "conv4_block1_add False\n",
      "conv4_block1_out False\n",
      "conv4_block2_1_conv False\n",
      "conv4_block2_1_bn False\n",
      "conv4_block2_1_relu False\n",
      "conv4_block2_2_conv False\n",
      "conv4_block2_2_bn False\n",
      "conv4_block2_2_relu False\n",
      "conv4_block2_3_conv False\n",
      "conv4_block2_3_bn False\n",
      "conv4_block2_add False\n",
      "conv4_block2_out False\n",
      "conv4_block3_1_conv False\n",
      "conv4_block3_1_bn False\n",
      "conv4_block3_1_relu True\n",
      "conv4_block3_2_conv True\n",
      "conv4_block3_2_bn True\n",
      "conv4_block3_2_relu True\n",
      "conv4_block3_3_conv True\n",
      "conv4_block3_3_bn True\n",
      "conv4_block3_add True\n",
      "conv4_block3_out True\n",
      "conv4_block4_1_conv True\n",
      "conv4_block4_1_bn True\n",
      "conv4_block4_1_relu True\n",
      "conv4_block4_2_conv True\n",
      "conv4_block4_2_bn True\n",
      "conv4_block4_2_relu True\n",
      "conv4_block4_3_conv True\n",
      "conv4_block4_3_bn True\n",
      "conv4_block4_add True\n",
      "conv4_block4_out True\n",
      "conv4_block5_1_conv True\n",
      "conv4_block5_1_bn True\n",
      "conv4_block5_1_relu True\n",
      "conv4_block5_2_conv True\n",
      "conv4_block5_2_bn True\n",
      "conv4_block5_2_relu True\n",
      "conv4_block5_3_conv True\n",
      "conv4_block5_3_bn True\n",
      "conv4_block5_add True\n",
      "conv4_block5_out True\n",
      "conv4_block6_1_conv True\n",
      "conv4_block6_1_bn True\n",
      "conv4_block6_1_relu True\n",
      "conv4_block6_2_conv True\n",
      "conv4_block6_2_bn True\n",
      "conv4_block6_2_relu True\n",
      "conv4_block6_3_conv True\n",
      "conv4_block6_3_bn True\n",
      "conv4_block6_add True\n",
      "conv4_block6_out True\n",
      "conv5_block1_1_conv True\n",
      "conv5_block1_1_bn True\n",
      "conv5_block1_1_relu True\n",
      "conv5_block1_2_conv True\n",
      "conv5_block1_2_bn True\n",
      "conv5_block1_2_relu True\n",
      "conv5_block1_0_conv True\n",
      "conv5_block1_3_conv True\n",
      "conv5_block1_0_bn True\n",
      "conv5_block1_3_bn True\n",
      "conv5_block1_add True\n",
      "conv5_block1_out True\n",
      "conv5_block2_1_conv True\n",
      "conv5_block2_1_bn True\n",
      "conv5_block2_1_relu True\n",
      "conv5_block2_2_conv True\n",
      "conv5_block2_2_bn True\n",
      "conv5_block2_2_relu True\n",
      "conv5_block2_3_conv True\n",
      "conv5_block2_3_bn True\n",
      "conv5_block2_add True\n",
      "conv5_block2_out True\n",
      "conv5_block3_1_conv True\n",
      "conv5_block3_1_bn True\n",
      "conv5_block3_1_relu True\n",
      "conv5_block3_2_conv True\n",
      "conv5_block3_2_bn True\n",
      "conv5_block3_2_relu True\n",
      "conv5_block3_3_conv True\n",
      "conv5_block3_3_bn True\n",
      "conv5_block3_add True\n",
      "conv5_block3_out True\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1752819113099,
     "user": {
      "displayName": "Bhawya Devi",
      "userId": "13879599296228198665"
     },
     "user_tz": -330
    },
    "id": "Ujl6OFwiKIn2",
    "outputId": "2a08ac51-6aee-43c4-e80f-5dc12c825c1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total layers: 175\n",
      "Trainable layers: 70 (last -70)\n",
      "Frozen layers: 105\n",
      "\n",
      "First 5 FROZEN layers:\n",
      "input_layer_2             | Trainable: False\n",
      "conv1_pad                 | Trainable: False\n",
      "conv1_conv                | Trainable: False\n",
      "conv1_bn                  | Trainable: False\n",
      "conv1_relu                | Trainable: False\n",
      "\n",
      "Last 5 TRAINABLE layers:\n",
      "conv5_block3_2_relu       | Trainable: True\n",
      "conv5_block3_3_conv       | Trainable: True\n",
      "conv5_block3_3_bn         | Trainable: True\n",
      "conv5_block3_add          | Trainable: True\n",
      "conv5_block3_out          | Trainable: True\n",
      "\n",
      "BatchNorm layer status:\n",
      "conv5_block3_1_bn         | Trainable: True (should typically be False)\n",
      "conv5_block3_2_bn         | Trainable: True (should typically be False)\n",
      "conv5_block3_3_bn         | Trainable: True (should typically be False)\n"
     ]
    }
   ],
   "source": [
    "# 1. First get the base ResNet50 model\n",
    "base_model = ResNet50(include_top=False, weights='imagenet')\n",
    "\n",
    "# 2. Apply your unfreezing logic\n",
    "phase = 3  # Your current phase\n",
    "freeze_until = -70  # Your setting for phase 3\n",
    "\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    layer.trainable = (i >= len(base_model.layers) + freeze_until ) # + because freeze_until is negative\n",
    "\n",
    "# 3. Count and display layer status\n",
    "total_layers = len(base_model.layers)\n",
    "trainable_layers = sum([1 for layer in base_model.layers if layer.trainable])\n",
    "frozen_layers = total_layers - trainable_layers\n",
    "\n",
    "print(f\"\\nTotal layers: {total_layers}\")\n",
    "print(f\"Trainable layers: {trainable_layers} (last {freeze_until})\")\n",
    "print(f\"Frozen layers: {frozen_layers}\\n\")\n",
    "\n",
    "# 4. Print the first 5 frozen and last 5 trainable layers\n",
    "print(\"First 5 FROZEN layers:\")\n",
    "for layer in base_model.layers[:5]:\n",
    "    print(f\"{layer.name:25} | Trainable: {layer.trainable}\")\n",
    "\n",
    "print(\"\\nLast 5 TRAINABLE layers:\")\n",
    "for layer in base_model.layers[-5:]:\n",
    "    print(f\"{layer.name:25} | Trainable: {layer.trainable}\")\n",
    "\n",
    "# 5. Verify BatchNorm layers are frozen (recommended)\n",
    "print(\"\\nBatchNorm layer status:\")\n",
    "bn_layers = [l for l in base_model.layers if 'bn' in l.name]\n",
    "for bn in bn_layers[-3:]:  # Print last 3 BN layers\n",
    "    print(f\"{bn.name:25} | Trainable: {bn.trainable} (should typically be False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517028,
     "status": "ok",
     "timestamp": 1753064999758,
     "user": {
      "displayName": "Bhawya Devi",
      "userId": "13879599296228198665"
     },
     "user_tz": -330
    },
    "id": "YnSZyI4lcOTW",
    "outputId": "922b2857-8a5e-4e38-f844-4583cb8d4078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "📊 Classification Report (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         MEL       0.42      0.40      0.41       362\n",
      "          NV       0.83      0.68      0.75      1030\n",
      "         BCC       0.53      0.38      0.45       266\n",
      "          AK       0.52      0.16      0.24        70\n",
      "         BKL       0.41      0.34      0.37       210\n",
      "          DF       0.55      0.32      0.40        19\n",
      "        VASC       0.83      0.25      0.38        20\n",
      "         SCC       0.29      0.10      0.15        50\n",
      "\n",
      "   micro avg       0.65      0.52      0.57      2027\n",
      "   macro avg       0.55      0.33      0.39      2027\n",
      "weighted avg       0.65      0.52      0.57      2027\n",
      " samples avg       0.51      0.52      0.51      2027\n",
      "\n",
      "✅ Exact Match Accuracy (Validation): 0.5067\n",
      "🔥 Macro AUC Score (Validation): 0.8355\n",
      "\n",
      "🔹 Per-class Accuracy (Validation):\n",
      "MEL: 0.7958\n",
      "NV: 0.7647\n",
      "BCC: 0.8752\n",
      "AK: 0.9660\n",
      "BKL: 0.8806\n",
      "DF: 0.9911\n",
      "VASC: 0.9921\n",
      "SCC: 0.9719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "# === Load your model architecture ===\n",
    "base_model = keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(75, 100, 3),\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "# Build your full model\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(8, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Load saved weights (change the path as needed)\n",
    "weights_path = \"/content/drive/MyDrive/Final_Project/Classification/Phase3_Augmented/reweights/resnet50_phase3_checkpoint.weights.h5\"\n",
    "model.load_weights(weights_path)\n",
    "\n",
    "# === Prepare your validation data generator ===\n",
    "# (Make sure val_gen is defined as in your training pipeline)\n",
    "# Example:\n",
    "# val_gen = SimpleNpyGenerator(val_image_paths, val_label_paths, batch_size=32)\n",
    "\n",
    "# Load full validation data into numpy arrays\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for batch_x, batch_y in val_gen:\n",
    "    x_val.append(batch_x)\n",
    "    y_val.append(batch_y)\n",
    "    # Stop after one full pass\n",
    "    if len(x_val) * val_gen.batch_size >= len(val_gen.image_paths):\n",
    "        break\n",
    "\n",
    "x_val = np.vstack(x_val)\n",
    "y_val = np.vstack(y_val)\n",
    "\n",
    "# === Predict on validation set ===\n",
    "y_pred = model.predict(x_val, verbose=0)\n",
    "\n",
    "# Binarize predictions at 0.5 threshold\n",
    "y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "# Calculate exact match accuracy (strict multi-label accuracy)\n",
    "exact_match_acc = accuracy_score(y_val, y_pred_binary)\n",
    "\n",
    "# Calculate macro AUC\n",
    "auc_score = roc_auc_score(y_val, y_pred, average='macro')\n",
    "\n",
    "# Print classification report\n",
    "print(\"📊 Classification Report (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_binary, target_names=[\n",
    "    'MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC'\n",
    "]))\n",
    "\n",
    "print(f\"✅ Exact Match Accuracy (Validation): {exact_match_acc:.4f}\")\n",
    "print(f\"🔥 Macro AUC Score (Validation): {auc_score:.4f}\")\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracies = (y_pred_binary == y_val).mean(axis=0)\n",
    "labels = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC']\n",
    "print(\"\\n🔹 Per-class Accuracy (Validation):\")\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"{label}: {class_accuracies[i]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNVkFVaZM7g7Ec/B/us2w7O",
   "gpuType": "T4",
   "mount_file_id": "11xpX8U2RiixVqFesLUn2O85f7T0leO5i",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
